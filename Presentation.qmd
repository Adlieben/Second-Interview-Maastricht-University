---
title: "Evaluating the Use of a Mortality Score in Admitting Covid-19 Patients into Dutch Hospitals"
author: 
  - name: Adam Maghout
    orcid: 0009-0002-5241-0856
    email: a.maghout@uu.nl
    affiliations:
      - name: Methodology & Statistics @ UU University
date: 19 Feb 2025
date-format: "D MMM YYYY"
execute: 
  echo: true
editor: source
bibliography: Bibliography.bib
format: 
  revealjs:
    embed-resources: true
    progress: true
    multiplex: true
    transition: fade
    slide-number: true
    margin: 0.075
    logo: "Images/logo.png" 
    toc: false
    toc-depth: 1
    toc-title: Outline
    scrollable: true
    reference-location: margin
    footer: Adam Maghout @ UU
    preview-links: true
    css: styles.css
---

```{r data load, echo=F, message=F, warning=F, include=F}
# Libraries
packages <- c("openxlsx", "tidyverse", "caret", "pROC", 
              "yardstick", "predtools", "dcurves", "gtsummary", "MASS")
install.packages(setdiff(packages, rownames(installed.packages())), 
                 dependencies = TRUE)
lapply(packages, library, character.only = TRUE)

# Load data
data <- read.xlsx("Data/covidpredict-1.xlsx")

# Separate training and test set
train <- data %>% filter(set == "dev")
test <- data %>% filter(set != "dev")
```

## Background

::: {.incremental}
- Development and validation of a pragmatic risk score to predict in-hospital mortality in patients admitted to hospital with covid-19.
- Analysis conducted in December 2021.
- In 2021 up until December, 1 870 640 new reported cases of covid-19 and 8 109 reported deaths [@COVID19DataWHO].
- Important to hospitalise at-risk patients without overburdening healthcare facilities.
:::

```{r WHO data manipulation, echo=F, message=F, warning=F, include=F}
# Load data
who <- read.csv("Data/WHO-COVID-19-global-data.csv") %>% 
  filter(Country_code == "NL") %>%
  filter(str_starts(as.character(Date_reported), "2021") & 
           as.character(Date_reported) < "2021-12") # remove December

inc <- sum(who$New_cases)
death <- sum(who$New_deaths)
```

## Data
<div class="slide-body">
Data is based on a prospective observational cohort study from @knightRiskStratificationPatients2020 in 260 hospitals across England, Scotland, and Wales, on adults (age â‰¥18 years) admitted to hospital between 6 February 2020 and 29 June 2020 with covid-19.

Although the original study included 35 463 patients in the derivation dataset and 22 361 in the validation dataset, the current dataset comprises of only:

```{r data 1, echo=F}
knitr::asis_output(
  sprintf(
    "<div>%d patients in the derivation set<br>%d patients in the validation set</div>",
    nrow(train), nrow(test)
  )
)
```
</div>

## Data
::: columns

::: column
<small>
  <ul>
    <li>`rr`: respiratory rate breaths/min.</li>
    <li>`oxygen_sat`: peripheral oxygen saturation in %.</li>
    <li>`urea`: urea level in mm/L.</li>
    <li>`crp`: C reactive protein in mg/L.</li>
    <li>`gcs`: level of consciousness on the Glasgow coma scale.</li>
    <li>`age`: age in years.</li>
    <li>`female`: sex (female = 1, male = 0).</li>
    <li>`comorbidity`: number of comorbidities, including obesity, chronic cardiac disease, etc.</li>
    <li>`date`: unit unclear.</li>
    <li>`set`: identifier for the development and validation sets.</li>
    <li>`mortality`: in-hospital mortality during study.</li>
  </ul>
</small>
:::

::: column
<div style="overflow-y: auto; max-height: 550px;">
```{r data 2, echo=F}
data %>% tbl_summary(type = all_dichotomous() ~ "categorical")
```
</div>
:::
:::

## Aims

::: {.incremental}
- Fitting a logistic model to predict `mortality` from the other variables.
- Conduct a Decision Curve Analysis (DCA) to evaluate the net benefit (NB) of using the model.
- Obtain the Expected Value of Perfect Information (EVPI) of the model.
:::

## Aims

![Population](Images/Population.png)

## Logistic Model

```{r logistic model}
#| code-line-numbers: "3"
model <- glm(mortality ~ age + female + comorbidity +
               rr + oxygen_sat + gcs + urea + crp,
             data = train,
             family = binomial)
summary(model)
```

## Temporal Validation

### Specificity, sensitivity, PPV and NPV

<small>
The model is now run on the validation set collected between 21 May and 29 June 2020.
</small>

```{r temp 1, echo=F}
test$predicted <- predict(model, test, type = "response")

conf_matrix <- confusionMatrix(factor(round(test$predicted)), 
                               factor(test$mortality))
print(conf_matrix)
```

## Temporal Validation

### Calibration plot

```{r temp 2, echo=F}
plot <- calibration_plot(data = test, obs = "mortality", pred = "predicted", 
                 y_lim = c(0, 1), x_lim=c(0, 1),
                 title = "Calibration plot for validation data")$calibration_plot
plot$layers[[1]]$aes_params$colour <- '#EFC251' # minor aesthetic tweak
plot$layers[[2]]$aes_params$colour <- '#EFC251'
plot
```

## Decision Curve Analysis

```{r DCA 1, echo=F, message=F}
dca_an <- dca(mortality ~ predicted, data = test)
plot(dca_an, smooth = TRUE, style = "bw")
```

## Decision Curve Analysis

Assuming that the risk threshold `z` above which patients are admitted to ICU is 10%:

```{r DCA 2, echo=T}
dca_an %>%
  as_tibble() %>%
  filter(threshold %in% seq(0.05, 0.15, by = 0.05)) %>%
  dplyr::select(variable, threshold, net_benefit) %>%
  pivot_wider(id_cols = threshold, 
              names_from = variable,
              values_from = net_benefit)
```

The net benefit of using the model is **0.003**.

## Decision Curve Analysis
### Implications of the net benefit

```{r DCA 3, echo=F}
NB <- 0.003 # observed above
z <- 0.1 #Risk threshold, given as 10%
```

The NB is defined as the proportion of additional true positives identified and:

$$
TP = \frac{z}{1-z}FP
$$

For 1000 patients:

```{r DCA 4, echo=T}
NB*1000 # gain in true positives
((1-z)/z)*NB*1000 # reduction in false positives
```

For 1 870 640 patients:

```{r DCA 5, echo=T}
NB*1870640 # gain in true positives
((1-z)/z)*NB*1870640 # reduction in false positives
```

## Decision Curve Analysis
### Decision

![Population](Images/Population 2.png)

## Value-of-information
### Expected Value of Perfect Information (EVPI)

An EVPI indicates how much NB is expected to be lost due to the model being imperfect. @sadatsafaviValueofInformationAnalysisExternal2023 propose several ways to compute it:

::: {.incremental}
- Bayesian bootstrapping
- Ordinary bootstrapping
- Asymptotic approach based on central limit theorem
:::

## Value-of-information



## Final Decision

## Challenges

::: {.incremental}
- Confusion surrounding the difference between an ordinary and a Bayesian bootstrap.
:::

## Conclusion

## Bibliography
